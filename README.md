# classification-with-NN 
# Классификация с помощью логистической регрессии, полносвязных и свёрточных нейронных сетей

## Описание

В данной работе исследуются различные подходы к задаче классификации на примере двух датасетов:
1. Искуственно сгенерированный набор данных (moons).
2. MNIST (рукописные цифры).

В ходе работы реализованы три основных метода:
- Логистическая регрессия (на PyTorch).
- Полносвязная нейронная сеть (fully connected neural network).
- Свёрточная нейронная сеть (LeNet).

Также было изучено качество обучения при различных функциях активации (ELU, ReLU, LeakyReLU и др.) 

### Задачи проекта:
1. Сбор и подготовка данных  
   - Для датасета moons: генерация, визуальный анализ, разбиение на обучающую и тестовую выборки.  
   - Для датасета MNIST: загрузка через torchvision, нормализация, подготовка DataLoader.

2. Обучение моделей  
   - Реализация логистической регрессии на PyTorch (BCEWithLogitsLoss).  
   - Реализация полносвязной нейронной сети с различными функциями активации (ReLU, LeakyReLU, ELU).  
   - Реализация свёрточной нейронной сети (LeNet) с классической архитектурой (Conv2D → Pool → … → Linear).

3. Анализ метрик и сравнение моделей  
   - Построение графиков Accuracy и Loss в процессе обучения.  
   - Оценка результатов (Accuracy на валидационной и тестовой выборках).

---

## Подробнее

Посмотреть подробный ноутбук (экспортированный в PDF) можно в репозитории:  
[Ссылка на блокнот](nn.ipynb)  

---

## Используемые библиотеки

### Библиотеки:
- numpy – для базовых операций с данными.
- matplotlib, seaborn – для визуализации (графики потерь, метрики, примеры изображений).
- scikit-learn – генерация датасета (moons), метрики (accuracy_score и пр.).
- torch, torchvision – реализация логистической регрессии, нейронных сетей.
- cv2 - для обработки изображений.

---

## Основные результаты

- Логистическая регрессия на датасете moons показала ~86% accuracy, что является неплохим результатом, учитывая простоту модели.
- Fully-connected NN на MNIST: при использовании функции активации ELU достигнута точность ~97% за 10 эпох обучения.
- LeNet на MNIST: точность на тестовой выборке превысила 98% (максимум ~99%) при 10 эпохах обучения.
- При сравнении функций активации (ReLU, LeakyReLU, ELU) ELU нередко давала более быструю сходимость и более высокое качество к концу обучения.

## Установка

Для работы с проектом потребуется установленный Python 3.x и следующие библиотеки:

`bash
pip install numpy matplotlib seaborn scikit-learn torch torchvision cv2
